{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(random_state=42))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(random_state=42)\n",
    "\n",
    "hard_voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)], voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "Hard voting clasifier accuracy:  0.912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "            \n",
    "hvc_predict = hard_voting_clf.predict(X_test)            \n",
    "print(\"Hard voting clasifier accuracy: \", accuracy_score(y_test, hvc_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(probability=True, random_state=42))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(probability=True, random_state=42)\n",
    "\n",
    "soft_voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, soft_voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging & Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    max_samples=100, bootstrap=False, n_jobs=-1, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_bag_clf = BaggingClassifier(\n",
    "    LogisticRegression(random_state=42), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1, random_state=42)\n",
    "lr_bag_clf.fit(X_train, y_train)\n",
    "lr_y_pred = lr_bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, lr_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of bag samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### oob_decision_function_ is returning calss probabilities as the base esitmator (DecisionTree) has got predict_proba() method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=42), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True, random_state=40)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, \\\n",
    "                                                 n_jobs=-1, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)  \n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import fetch_mldata\n",
    "digit_dataset = pd.read_csv('../dataset/digit_recognizer_train.csv')\n",
    "digit_X = digit_dataset.iloc[:, 1:]\n",
    "digit_y = digit_dataset['label']\n",
    "digit_X_train, digit_X_test, digit_y_train, digit_y_test = \\\n",
    "                                    train_test_split(digit_X, digit_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "rnd_clf.fit(digit_X_train, digit_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "  * if you look at a single Decision Tree, important features are likely to appear closer to the root of the tree, \n",
    "    while unimportant features will often appear closer to the leaves (or not at all). \n",
    "    It is therefore possible to get an estimate of a feature’s importance by computing the average depth at which it \n",
    "    appears across all trees in the forest. Scikit-Learn computes this automatically for every feature after training. \n",
    "    You can access the result using the feature\\_importances\\_ variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.95685473e-06, 6.58732394e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.86013982e-06, 2.57240945e-06,\n",
       "       1.67148095e-06, 6.91803381e-06, 2.37880357e-06, 3.01191413e-06,\n",
       "       2.85137901e-06, 5.45432808e-06, 0.00000000e+00, 1.81954707e-06,\n",
       "       6.10203147e-06, 2.95866817e-06, 1.28444593e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.30028644e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.02879380e-06,\n",
       "       0.00000000e+00, 6.46532368e-07, 6.57333713e-07, 2.75732693e-06,\n",
       "       1.40038758e-05, 7.02778062e-05, 2.93561901e-05, 1.02995230e-04,\n",
       "       9.64703398e-05, 1.19778696e-04, 1.10010411e-04, 1.18761240e-04,\n",
       "       3.18636210e-04, 8.37763122e-05, 1.11391537e-04, 8.43303662e-05,\n",
       "       3.04248075e-05, 4.99703373e-06, 1.09589056e-05, 3.00466760e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.51382987e-07,\n",
       "       0.00000000e+00, 3.73519046e-06, 1.06614319e-05, 3.43317712e-05,\n",
       "       1.05805208e-04, 1.20101837e-04, 2.14067805e-04, 4.17540181e-04,\n",
       "       3.71533599e-04, 1.24673904e-03, 1.44671495e-03, 2.76519217e-03,\n",
       "       2.02932112e-03, 1.78285161e-03, 1.36943108e-03, 1.01625070e-03,\n",
       "       4.39584810e-04, 8.40178813e-05, 5.09425995e-05, 2.98604787e-05,\n",
       "       1.22970157e-05, 5.76004973e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.10518640e-06,\n",
       "       4.24792948e-06, 6.06808929e-06, 3.56739659e-05, 7.81760410e-05,\n",
       "       2.22215888e-04, 5.17584159e-04, 7.49985311e-04, 1.19436999e-03,\n",
       "       1.77222003e-03, 1.95830075e-03, 1.98537836e-03, 2.07323431e-03,\n",
       "       1.48933716e-03, 1.17294294e-03, 9.56432435e-04, 5.82424281e-04,\n",
       "       4.42473866e-04, 2.16076468e-04, 1.23612815e-04, 7.42073994e-05,\n",
       "       3.65472103e-05, 8.44224909e-06, 3.30841535e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.63163011e-06,\n",
       "       1.00006022e-05, 4.10522382e-05, 1.07321935e-04, 2.26644228e-04,\n",
       "       5.55106698e-04, 1.27005251e-03, 1.68836583e-03, 3.20894170e-03,\n",
       "       3.61007605e-03, 4.83831303e-03, 5.98510874e-03, 6.48492798e-03,\n",
       "       4.06780144e-03, 2.85821973e-03, 2.37385550e-03, 1.38466083e-03,\n",
       "       8.18400782e-04, 8.34255101e-04, 5.66682768e-04, 3.36400998e-04,\n",
       "       1.46312532e-04, 2.11789601e-05, 2.48765617e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.85124949e-06, 3.98796148e-06,\n",
       "       3.83492101e-05, 1.06537672e-04, 3.01468602e-04, 4.80679079e-04,\n",
       "       9.68815893e-04, 1.74457547e-03, 2.68012228e-03, 1.91567538e-03,\n",
       "       2.96597857e-03, 2.65057865e-03, 4.24277027e-03, 4.98433607e-03,\n",
       "       3.15692941e-03, 3.55272946e-03, 2.23033377e-03, 1.67264889e-03,\n",
       "       1.33206366e-03, 1.27665614e-03, 1.00186881e-03, 1.25356850e-03,\n",
       "       4.61897241e-04, 3.92249148e-05, 1.68294423e-05, 1.05694836e-06,\n",
       "       0.00000000e+00, 1.42126545e-06, 2.10380753e-06, 2.23267027e-05,\n",
       "       8.48672689e-05, 1.75709748e-04, 3.01397402e-04, 6.88829728e-04,\n",
       "       8.50520210e-04, 1.72141338e-03, 1.97217219e-03, 2.55132184e-03,\n",
       "       2.60400895e-03, 3.57431244e-03, 6.50764688e-03, 5.96578860e-03,\n",
       "       4.79103255e-03, 2.76745807e-03, 2.92374547e-03, 2.03151924e-03,\n",
       "       1.90708861e-03, 1.10989358e-03, 1.03652361e-03, 1.01873339e-03,\n",
       "       7.67004905e-04, 1.01395680e-04, 2.37108674e-05, 0.00000000e+00,\n",
       "       1.12917174e-06, 0.00000000e+00, 4.13497011e-06, 2.58910901e-05,\n",
       "       1.06830240e-04, 1.56909791e-04, 3.22181754e-04, 7.35974365e-04,\n",
       "       1.32567746e-03, 2.81038264e-03, 3.17835632e-03, 3.14862664e-03,\n",
       "       3.39235907e-03, 4.92436475e-03, 4.91163318e-03, 5.20878614e-03,\n",
       "       4.92307919e-03, 3.27002015e-03, 3.37254741e-03, 3.00267411e-03,\n",
       "       1.81795910e-03, 1.78420100e-03, 1.04627837e-03, 1.13145451e-03,\n",
       "       8.16219454e-04, 2.08516224e-04, 1.79605297e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 6.11501792e-07, 1.00346366e-05, 2.69632351e-05,\n",
       "       9.51450824e-05, 2.23613683e-04, 3.94827334e-04, 8.00864874e-04,\n",
       "       1.71894327e-03, 2.47848786e-03, 3.42721456e-03, 4.85807123e-03,\n",
       "       3.39047289e-03, 3.57901829e-03, 3.85768760e-03, 3.98057440e-03,\n",
       "       3.82556253e-03, 3.73721563e-03, 4.41917074e-03, 3.75514350e-03,\n",
       "       2.45315744e-03, 1.80352631e-03, 9.58267207e-04, 7.18437901e-04,\n",
       "       4.09872405e-04, 2.04467132e-04, 1.74322114e-05, 1.15352846e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 8.73888016e-06, 2.80288332e-05,\n",
       "       1.01563930e-04, 2.79698567e-04, 3.69536502e-04, 9.16068772e-04,\n",
       "       1.47975909e-03, 2.55581353e-03, 6.02628820e-03, 4.10180665e-03,\n",
       "       3.29525618e-03, 2.87787934e-03, 3.55047417e-03, 3.92799712e-03,\n",
       "       3.69089431e-03, 4.39937016e-03, 4.48608064e-03, 4.02155406e-03,\n",
       "       2.67323099e-03, 2.48035323e-03, 1.08920101e-03, 3.58588085e-04,\n",
       "       2.20961896e-04, 6.28050064e-05, 1.65228509e-05, 1.62856715e-06,\n",
       "       0.00000000e+00, 1.03445697e-06, 9.80941986e-06, 4.18195937e-05,\n",
       "       8.83973674e-05, 2.88260505e-04, 6.36711704e-04, 1.21052896e-03,\n",
       "       2.49855127e-03, 4.16677629e-03, 6.05066455e-03, 4.96924418e-03,\n",
       "       3.24758025e-03, 3.13605066e-03, 4.84013521e-03, 5.76987330e-03,\n",
       "       2.90658505e-03, 3.12785543e-03, 4.44430234e-03, 3.09892912e-03,\n",
       "       1.77951511e-03, 1.90742240e-03, 1.48180026e-03, 4.32888312e-04,\n",
       "       1.59269490e-04, 3.01385488e-05, 7.94528237e-06, 2.93506851e-06,\n",
       "       0.00000000e+00, 6.34070399e-07, 4.97099122e-06, 2.20771765e-05,\n",
       "       9.23447508e-05, 2.13699737e-04, 8.09477738e-04, 1.56587777e-03,\n",
       "       2.07650673e-03, 4.20273245e-03, 5.36121160e-03, 6.82531766e-03,\n",
       "       4.02182265e-03, 4.57199928e-03, 7.94537962e-03, 6.23957525e-03,\n",
       "       3.54507884e-03, 4.72055169e-03, 4.20657994e-03, 2.11096877e-03,\n",
       "       1.71880916e-03, 1.85889542e-03, 1.85775130e-03, 6.69770799e-04,\n",
       "       8.29546118e-05, 2.29933618e-05, 1.17831221e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 9.92317371e-07, 1.96449351e-05,\n",
       "       6.60485416e-05, 2.80289211e-04, 8.34866507e-04, 1.78729550e-03,\n",
       "       2.93418384e-03, 5.07497167e-03, 5.27868234e-03, 6.07196004e-03,\n",
       "       4.32874767e-03, 6.80539392e-03, 7.59625002e-03, 4.77612064e-03,\n",
       "       4.21124198e-03, 5.62048850e-03, 4.32361702e-03, 1.91932768e-03,\n",
       "       1.16570091e-03, 1.82094929e-03, 1.70888402e-03, 5.42063774e-04,\n",
       "       1.47128624e-04, 4.32358612e-05, 1.04884627e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.41152232e-06, 2.02727454e-05,\n",
       "       7.07327100e-05, 2.36790282e-04, 1.25981375e-03, 1.55068596e-03,\n",
       "       4.44974019e-03, 5.31460231e-03, 5.55513849e-03, 4.10659890e-03,\n",
       "       4.91913831e-03, 7.09179580e-03, 8.09040413e-03, 4.26624916e-03,\n",
       "       3.07625023e-03, 7.21237866e-03, 3.29383577e-03, 1.55794482e-03,\n",
       "       1.61511606e-03, 1.04591608e-03, 1.33808639e-03, 7.28233485e-04,\n",
       "       2.12540173e-04, 2.82813275e-05, 1.03059131e-05, 1.27987196e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.26871197e-06, 1.53966047e-05,\n",
       "       6.63340124e-05, 4.53665947e-04, 1.33618665e-03, 4.01811708e-03,\n",
       "       5.23418377e-03, 4.50680021e-03, 4.53557691e-03, 4.47001794e-03,\n",
       "       4.17089943e-03, 8.73341711e-03, 4.79907013e-03, 4.27525199e-03,\n",
       "       3.62286048e-03, 5.60172400e-03, 2.21031995e-03, 1.70954992e-03,\n",
       "       1.60221923e-03, 1.39122837e-03, 1.43081863e-03, 3.81702144e-04,\n",
       "       1.58625050e-04, 3.69941520e-05, 1.33007717e-05, 1.19142587e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.49289079e-06, 1.66841209e-05,\n",
       "       1.24409510e-04, 4.12733359e-04, 1.95625004e-03, 2.70632887e-03,\n",
       "       2.80827170e-03, 4.57584803e-03, 4.49709261e-03, 5.03092402e-03,\n",
       "       6.92076689e-03, 8.41399355e-03, 4.99753593e-03, 2.83836552e-03,\n",
       "       2.64315382e-03, 4.50193345e-03, 2.81322427e-03, 1.86889444e-03,\n",
       "       2.02009802e-03, 1.02999847e-03, 1.17123275e-03, 3.42725758e-04,\n",
       "       1.35370572e-04, 4.90574415e-05, 1.89625608e-05, 2.82774483e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.27671112e-06, 4.15660512e-05,\n",
       "       1.09089407e-04, 9.86537458e-04, 1.77711016e-03, 2.16751108e-03,\n",
       "       2.84439337e-03, 3.79595478e-03, 5.47091394e-03, 5.09098117e-03,\n",
       "       4.91881557e-03, 6.34858866e-03, 4.04122544e-03, 2.54768663e-03,\n",
       "       2.14203658e-03, 2.24634556e-03, 2.02845858e-03, 2.26323991e-03,\n",
       "       1.70099884e-03, 1.71473221e-03, 5.57442369e-04, 3.42251981e-04,\n",
       "       1.82380449e-04, 5.50228887e-05, 1.49168795e-05, 6.15195797e-06,\n",
       "       0.00000000e+00, 1.27510845e-06, 6.08231660e-06, 5.92883709e-05,\n",
       "       1.48608363e-04, 5.20206316e-04, 1.57692548e-03, 2.46723092e-03,\n",
       "       2.72860947e-03, 4.02870388e-03, 5.48410758e-03, 5.83582150e-03,\n",
       "       4.56517190e-03, 3.64750579e-03, 3.13669853e-03, 1.84940689e-03,\n",
       "       1.20532259e-03, 2.59553455e-03, 2.87621563e-03, 1.83980912e-03,\n",
       "       1.48307023e-03, 9.46027000e-04, 5.60590153e-04, 4.48604385e-04,\n",
       "       1.40588428e-04, 5.09541041e-05, 9.22742328e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.99085529e-06, 5.11068005e-05,\n",
       "       1.63600376e-04, 6.00231025e-04, 1.09784285e-03, 2.83253308e-03,\n",
       "       3.61985706e-03, 5.38668326e-03, 6.64648556e-03, 6.34480571e-03,\n",
       "       3.33002712e-03, 2.36193225e-03, 1.92106982e-03, 1.49906195e-03,\n",
       "       1.79337512e-03, 1.89035269e-03, 2.40985147e-03, 2.05172219e-03,\n",
       "       2.09532620e-03, 1.10789999e-03, 9.46232091e-04, 3.43200977e-04,\n",
       "       1.23014362e-04, 4.72608980e-05, 5.07842243e-06, 5.29349494e-07,\n",
       "       0.00000000e+00, 6.51538795e-07, 3.52802075e-06, 6.05140127e-05,\n",
       "       2.56263255e-04, 7.47774443e-04, 1.28323029e-03, 3.28789190e-03,\n",
       "       4.72606207e-03, 5.47673195e-03, 3.61848620e-03, 3.68631075e-03,\n",
       "       3.13157231e-03, 2.07163932e-03, 2.01003113e-03, 2.01688828e-03,\n",
       "       1.33001666e-03, 1.77881523e-03, 2.05644186e-03, 1.49294914e-03,\n",
       "       1.27407469e-03, 9.27674678e-04, 5.54516692e-04, 3.31823202e-04,\n",
       "       1.07381412e-04, 2.53490090e-05, 6.42707213e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.27366311e-06, 7.46872091e-06, 6.12365764e-05,\n",
       "       2.31733050e-04, 4.21912778e-04, 1.18926151e-03, 3.35608378e-03,\n",
       "       5.64775647e-03, 4.91716894e-03, 2.42590845e-03, 1.55544425e-03,\n",
       "       1.54640554e-03, 1.46249341e-03, 1.49010266e-03, 1.37585539e-03,\n",
       "       1.08347792e-03, 1.22505372e-03, 1.57196078e-03, 1.28191144e-03,\n",
       "       1.03716693e-03, 5.59912108e-04, 3.70671855e-04, 1.40005082e-04,\n",
       "       9.56514056e-05, 1.65945327e-05, 1.96066876e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.90534958e-06, 1.89958768e-05,\n",
       "       1.18129621e-04, 2.61449484e-04, 8.62390595e-04, 2.01432763e-03,\n",
       "       3.28468084e-03, 3.36739005e-03, 4.13433804e-03, 2.23984784e-03,\n",
       "       1.94999576e-03, 1.45231963e-03, 2.08173741e-03, 1.55682280e-03,\n",
       "       1.35020802e-03, 1.01040763e-03, 7.96235328e-04, 7.42395918e-04,\n",
       "       4.52959130e-04, 2.68745703e-04, 1.75246026e-04, 7.98421286e-05,\n",
       "       2.27774646e-05, 1.04594749e-05, 3.30798369e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 8.82140020e-07, 1.62738020e-05,\n",
       "       7.51903181e-05, 2.18648394e-04, 3.77899421e-04, 7.68450142e-04,\n",
       "       1.05679625e-03, 1.89646008e-03, 3.44985933e-03, 4.40896701e-03,\n",
       "       4.42648554e-03, 4.08472961e-03, 4.33874939e-03, 2.06704227e-03,\n",
       "       1.74626465e-03, 9.95832706e-04, 7.52989928e-04, 4.18024719e-04,\n",
       "       2.40359844e-04, 1.23529389e-04, 6.32744815e-05, 3.94101561e-05,\n",
       "       1.37054712e-05, 3.87034454e-06, 1.14689014e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.06033793e-06, 1.80145834e-05,\n",
       "       4.42362587e-05, 1.07171214e-04, 2.28136974e-04, 4.22501536e-04,\n",
       "       5.04289641e-04, 8.83421651e-04, 9.58922718e-04, 1.30286595e-03,\n",
       "       1.85113747e-03, 1.87776254e-03, 1.05170693e-03, 7.42516202e-04,\n",
       "       5.76149926e-04, 4.57438088e-04, 3.18284247e-04, 2.08137049e-04,\n",
       "       1.50345219e-04, 8.50837886e-05, 5.82122984e-05, 1.98575569e-05,\n",
       "       5.49530702e-06, 1.82929836e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.27465464e-06,\n",
       "       1.91581022e-05, 5.94510545e-05, 1.15882721e-04, 1.71947646e-04,\n",
       "       2.74429782e-04, 7.32564372e-04, 5.55520875e-04, 6.48255002e-04,\n",
       "       6.62126640e-04, 6.05786810e-04, 6.15293817e-04, 3.83105458e-04,\n",
       "       4.04481668e-04, 3.72784443e-04, 3.98615107e-04, 2.26804636e-04,\n",
       "       7.63301806e-05, 3.43851025e-05, 2.10271338e-05, 8.11448167e-06,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       4.02550956e-06, 1.92731557e-05, 1.07673095e-05, 2.84545142e-05,\n",
       "       4.54174947e-05, 4.49927582e-05, 7.93352663e-05, 1.41654800e-04,\n",
       "       2.71899300e-04, 1.10314327e-04, 2.34467985e-04, 1.43623071e-04,\n",
       "       1.33975784e-04, 1.50136281e-04, 8.11495347e-05, 5.63662291e-05,\n",
       "       1.20593966e-05, 9.79856787e-06, 3.62228043e-06, 6.52803224e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.51361257e-07,\n",
       "       1.90731671e-06, 6.07750447e-07, 1.74572827e-06, 6.49143838e-06,\n",
       "       1.63253289e-06, 4.42565324e-06, 1.02632532e-05, 3.21004839e-06,\n",
       "       3.44478230e-06, 4.11265869e-06, 7.26254405e-06, 2.33789971e-06,\n",
       "       2.49489592e-06, 5.51334937e-07, 1.24981099e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel432 0.008733417110655927\n",
      "pixel460 0.008413993554574251\n",
      "pixel405 0.008090404130597752\n",
      "pixel349 0.00794537962198465\n",
      "pixel377 0.007596250021411368\n",
      "pixel408 0.007212378662906189\n",
      "pixel404 0.007091795798950185\n",
      "pixel459 0.006920766891424367\n",
      "pixel346 0.006825317663935314\n",
      "pixel376 0.0068053939235530655\n",
      "pixel541 0.006646485555546839\n",
      "pixel209 0.006507646876740392\n",
      "pixel154 0.006484927980250387\n",
      "pixel488 0.0063485886552726\n",
      "pixel542 0.006344805713061915\n",
      "pixel350 0.006239575252241664\n",
      "pixel374 0.006071960041463447\n",
      "pixel317 0.006050664550252324\n",
      "pixel289 0.006026288204801286\n",
      "pixel153 0.00598510873813774\n",
      "pixel210 0.0059657885974518975\n",
      "pixel514 0.005835821498373061\n",
      "pixel322 0.005769873298390828\n",
      "pixel595 0.005647756467591681\n",
      "pixel380 0.005620488495407564\n",
      "pixel436 0.005601724003420501\n",
      "pixel401 0.005555138491047325\n",
      "pixel513 0.005484107582954661\n",
      "pixel568 0.005476731947757119\n",
      "pixel485 0.005470913941614827\n",
      "pixel540 0.005386683264786126\n",
      "pixel345 0.005361211599027789\n",
      "pixel400 0.005314602306428785\n",
      "pixel373 0.005278682338487605\n",
      "pixel427 0.005234183766132953\n",
      "pixel238 0.0052087861381856435\n",
      "pixel486 0.005090981174029792\n",
      "pixel372 0.005074971672175582\n",
      "pixel458 0.005030924020249302\n",
      "pixel461 0.0049975359322866125\n",
      "pixel182 0.004984336070038192\n",
      "pixel318 0.0049692441833792894\n",
      "pixel236 0.004924364751288987\n",
      "pixel239 0.004923079186068296\n",
      "pixel403 0.0049191383097050645\n",
      "pixel487 0.00491881557008029\n",
      "pixel596 0.0049171689423946514\n",
      "pixel237 0.004911633181505912\n",
      "pixel262 0.0048580712319855395\n",
      "pixel321 0.004840135208646297\n",
      "pixel152 0.004838313031784126\n",
      "pixel433 0.004799070131247297\n",
      "pixel211 0.004791032552962403\n",
      "pixel378 0.004776120640705654\n",
      "pixel567 0.0047260620707069954\n",
      "pixel352 0.004720551694456801\n",
      "pixel456 0.004575848025951718\n",
      "pixel348 0.004571999284256233\n",
      "pixel515 0.004565171896387917\n",
      "pixel429 0.0045355769114590475\n",
      "pixel428 0.004506800208130549\n",
      "pixel464 0.004501933452635648\n",
      "pixel457 0.004497092612184462\n",
      "pixel297 0.004486080640048397\n",
      "pixel430 0.004470017939423682\n",
      "pixel399 0.004449740190197355\n",
      "pixel325 0.004444302341773387\n",
      "pixel655 0.004426485542305955\n",
      "pixel269 0.00441917073894793\n",
      "pixel654 0.00440896701238289\n",
      "pixel296 0.004399370161471441\n",
      "pixel657 0.004338749394928062\n",
      "pixel375 0.00432874766757954\n",
      "pixel381 0.0043236170183478355\n",
      "pixel434 0.004275251991538568\n",
      "pixel406 0.004266249163768218\n",
      "pixel181 0.004242770273211009\n",
      "pixel379 0.004211241976682519\n",
      "pixel353 0.004206579942746749\n",
      "pixel344 0.004202732448282654\n",
      "pixel431 0.004170899425749578\n",
      "pixel316 0.004166776285420913\n",
      "pixel625 0.0041343380381043335\n",
      "pixel402 0.004106598900870743\n",
      "pixel290 0.00410180665304675\n",
      "pixel656 0.004084729612797367\n",
      "pixel155 0.004067801436671828\n",
      "pixel489 0.004041225441972255\n",
      "pixel512 0.00402870387629097\n",
      "pixel347 0.004021822650385245\n",
      "pixel298 0.004021554061683312\n",
      "pixel426 0.004018117082948094\n",
      "pixel266 0.003980574402500898\n",
      "pixel294 0.003927997124400007\n",
      "pixel265 0.0038576875983883903\n",
      "pixel267 0.003825562532366481\n",
      "pixel484 0.0037959547784852036\n",
      "pixel270 0.0037551434970648358\n",
      "pixel268 0.0037372156258380774\n",
      "pixel295 0.0036908943091881158\n",
      "pixel570 0.0036863107473415918\n",
      "pixel516 0.0036475057905661057\n",
      "pixel435 0.0036228604760262274\n",
      "pixel539 0.00361985706335754\n",
      "pixel569 0.0036184861954730186\n",
      "pixel151 0.0036100760530606898\n",
      "pixel264 0.0035790182930998103\n",
      "pixel208 0.0035743124377159057\n",
      "pixel184 0.0035527294617863463\n",
      "pixel293 0.003550474168432564\n",
      "pixel351 0.0035450788441688395\n",
      "pixel653 0.0034498593316343706\n",
      "pixel261 0.003427214562704895\n",
      "pixel235 0.0033923590679627367\n",
      "pixel263 0.003390472889468858\n",
      "pixel241 0.0033725474143467098\n",
      "pixel624 0.003367390050552614\n",
      "pixel594 0.0033560837786056645\n",
      "pixel543 0.0033300271193133072\n",
      "pixel291 0.003295256180385479\n",
      "pixel409 0.0032938357747640777\n",
      "pixel566 0.003287891901908157\n",
      "pixel623 0.0032846808447472126\n",
      "pixel240 0.003270020152145881\n",
      "pixel319 0.0032475802510695774\n",
      "pixel150 0.0032089417033142106\n",
      "pixel233 0.003178356317629495\n",
      "pixel183 0.003156929407941178\n",
      "pixel234 0.003148626642493273\n",
      "pixel517 0.0031366985305997692\n",
      "pixel320 0.0031360506613007616\n",
      "pixel571 0.0031315723084553247\n",
      "pixel324 0.003127855430596656\n",
      "pixel326 0.0030989291196827696\n",
      "pixel407 0.003076250229064132\n",
      "pixel242 0.0030026741131703115\n",
      "pixel179 0.0029659785744615484\n",
      "pixel371 0.002934183843544427\n",
      "pixel213 0.0029237454709367056\n",
      "pixel323 0.0029065850536279967\n",
      "pixel292 0.0028778793442489426\n",
      "pixel521 0.0028762156273681506\n",
      "pixel156 0.00285821973135299\n",
      "pixel483 0.002844393369207694\n",
      "pixel462 0.0028383655160919914\n",
      "pixel538 0.0028325330786721954\n",
      "pixel465 0.0028132242682913583\n",
      "pixel232 0.0028103826379582406\n",
      "pixel455 0.0028082716952356353\n",
      "pixel212 0.002767458069543948\n",
      "pixel98 0.0027651921728756228\n",
      "pixel511 0.002728609471340575\n",
      "pixel454 0.0027063288742545668\n",
      "pixel177 0.002680122277836572\n",
      "pixel299 0.0026732309859117333\n",
      "pixel180 0.0026505786477006603\n",
      "pixel463 0.00264315382478647\n",
      "pixel207 0.002604008948881423\n",
      "pixel520 0.0025955345469874935\n",
      "pixel288 0.002555813528621516\n",
      "pixel206 0.0025513218359608566\n",
      "pixel490 0.002547686632647993\n",
      "pixel315 0.0024985512660709304\n",
      "pixel300 0.0024803532346715364\n",
      "pixel260 0.0024784878578261674\n",
      "pixel510 0.002467230924015153\n",
      "pixel271 0.0024531574383224366\n",
      "pixel597 0.0024259084524480955\n",
      "pixel549 0.002409851470585967\n",
      "pixel157 0.0023738554994817717\n",
      "pixel544 0.0023619322536618122\n",
      "pixel494 0.002263239905338306\n",
      "pixel492 0.0022463455558652556\n",
      "pixel626 0.0022398478373545326\n",
      "pixel185 0.0022303337718377714\n",
      "pixel437 0.0022103199484544466\n",
      "pixel482 0.0021675110790670463\n",
      "pixel491 0.0021420365823431237\n",
      "pixel354 0.0021109687739470895\n",
      "pixel551 0.002095326199706653\n",
      "pixel629 0.0020817374094245066\n",
      "pixel343 0.0020765067336469497\n",
      "pixel126 0.0020732343055888123\n",
      "pixel572 0.0020716393182217525\n",
      "pixel658 0.002067042273350838\n",
      "pixel577 0.002056441856536164\n",
      "pixel550 0.002051722194197273\n",
      "pixel214 0.002031519239443681\n",
      "pixel99 0.002029321121481372\n",
      "pixel493 0.0020284585757540117\n",
      "pixel467 0.002020098018271942\n",
      "pixel574 0.002016888280630905\n",
      "pixel622 0.0020143276341154084\n",
      "pixel573 0.0020100311345545366\n",
      "pixel125 0.0019853783568926147\n",
      "pixel205 0.001972172193460353\n",
      "pixel124 0.0019583007515030964\n",
      "pixel453 0.001956250037476423\n",
      "pixel627 0.0019499957609846346\n",
      "pixel545 0.001921069815250735\n",
      "pixel382 0.0019193276799103084\n",
      "pixel178 0.0019156753839487453\n",
      "pixel328 0.0019074224019411023\n",
      "pixel215 0.0019070886131859132\n",
      "pixel652 0.00189646008236889\n",
      "pixel548 0.0018903526874859391\n",
      "pixel684 0.001877762536728488\n",
      "pixel466 0.0018688944426775034\n",
      "pixel356 0.0018588954244647378\n",
      "pixel357 0.0018577513031401193\n",
      "pixel683 0.0018511374691048401\n",
      "pixel518 0.0018494068897019595\n",
      "pixel522 0.001839809115271325\n",
      "pixel384 0.0018209492901952687\n",
      "pixel243 0.0018179590969100868\n",
      "pixel272 0.001803526314108535\n",
      "pixel547 0.0017933751220272792\n",
      "pixel370 0.0017872954972862128\n",
      "pixel244 0.0017842009979018461\n",
      "pixel100 0.0017828516064736736\n",
      "pixel327 0.0017795151136665596\n",
      "pixel576 0.0017788152259086282\n",
      "pixel481 0.0017771101613839554\n",
      "pixel123 0.001772220026635995\n",
      "pixel659 0.001746264653670608\n",
      "pixel176 0.001744575468918286\n",
      "pixel204 0.0017214133792360967\n",
      "pixel259 0.0017189432676651348\n",
      "pixel355 0.001718809155339408\n",
      "pixel496 0.0017147322073256595\n",
      "pixel438 0.001709549917613684\n",
      "pixel385 0.0017088840231658652\n",
      "pixel495 0.0017009988429454123\n",
      "pixel149 0.001688365832641014\n",
      "pixel186 0.0016726488891188615\n",
      "pixel411 0.0016151160556386128\n",
      "pixel439 0.0016022192342562257\n",
      "pixel509 0.0015769254802541625\n",
      "pixel605 0.0015719607752596682\n",
      "pixel342 0.0015658777738429936\n",
      "pixel410 0.0015579448177665543\n",
      "pixel630 0.0015568227991604414\n",
      "pixel598 0.001555444249429388\n",
      "pixel398 0.0015506859554968153\n",
      "pixel599 0.0015464055351110078\n",
      "pixel546 0.0014990619514941058\n",
      "pixel578 0.0014929491406279838\n",
      "pixel601 0.0014901026615468766\n",
      "pixel127 0.0014893371606882317\n",
      "pixel523 0.0014830702283688518\n",
      "pixel329 0.0014818002600393123\n",
      "pixel287 0.0014797590894687462\n",
      "pixel600 0.0014624934060090081\n",
      "pixel628 0.001452319634381913\n",
      "pixel97 0.0014467149467117392\n",
      "pixel441 0.0014308186339086822\n",
      "pixel440 0.0013912283698270817\n",
      "pixel158 0.0013846608337153641\n",
      "pixel602 0.0013758553875163131\n",
      "pixel101 0.0013694310830921475\n",
      "pixel631 0.00135020802116122\n",
      "pixel413 0.0013380863895533766\n",
      "pixel425 0.0013361866538148459\n",
      "pixel187 0.0013320636579780235\n",
      "pixel575 0.0013300166647561501\n",
      "pixel231 0.001325677455359054\n",
      "pixel682 0.0013028659508602597\n",
      "pixel565 0.0012832302934398542\n",
      "pixel606 0.0012819114401465587\n",
      "pixel188 0.0012766561412004172\n",
      "pixel579 0.0012740746915627355\n",
      "pixel148 0.0012700525143365365\n",
      "pixel397 0.0012598137548198265\n",
      "pixel190 0.0012535684961758205\n",
      "pixel96 0.0012467390436581157\n",
      "pixel604 0.001225053721363519\n",
      "pixel314 0.001210528964456036\n",
      "pixel519 0.0012053225873734823\n",
      "pixel122 0.0011943699872033109\n",
      "pixel593 0.0011892615056574532\n",
      "pixel128 0.001172942939390603\n",
      "pixel469 0.0011712327461543487\n",
      "pixel383 0.0011657009091611261\n",
      "pixel246 0.0011314545126816329\n",
      "pixel216 0.0011098935784503118\n",
      "pixel552 0.0011078999916341213\n",
      "pixel537 0.0010978428502181562\n",
      "pixel301 0.0010892010148802176\n",
      "pixel603 0.0010834779189388376\n",
      "pixel651 0.0010567962526670351\n",
      "pixel685 0.0010517069326769443\n",
      "pixel245 0.0010462783676435472\n",
      "pixel412 0.0010459160796281273\n",
      "pixel607 0.0010371669339177758\n",
      "pixel217 0.0010365236056247083\n",
      "pixel468 0.0010299984742022854\n",
      "pixel218 0.0010187333916011774\n",
      "pixel102 0.001016250698404463\n",
      "pixel632 0.0010104076310154518\n",
      "pixel189 0.00100186881392441\n",
      "pixel660 0.0009958327057532949\n",
      "pixel480 0.0009865374576909852\n",
      "pixel175 0.0009688158931757229\n",
      "pixel681 0.000958922717628907\n",
      "pixel273 0.0009582672074175642\n",
      "pixel129 0.0009564324352570601\n",
      "pixel553 0.0009462320907861914\n",
      "pixel524 0.0009460270000096773\n",
      "pixel580 0.0009276746777274924\n",
      "pixel286 0.0009160687717392444\n",
      "pixel680 0.0008834216509375117\n",
      "pixel621 0.0008623905954758948\n",
      "pixel203 0.0008505202095881598\n",
      "pixel369 0.0008348665070660965\n",
      "pixel160 0.0008342551010753207\n",
      "pixel159 0.000818400782057565\n",
      "pixel247 0.0008162194542618083\n",
      "pixel341 0.0008094777383899464\n",
      "pixel258 0.0008008648738396834\n",
      "pixel633 0.00079623532765599\n",
      "pixel650 0.0007684501418092749\n",
      "pixel219 0.0007670049050565785\n",
      "pixel661 0.0007529899275684418\n",
      "pixel121 0.0007499853106845715\n",
      "pixel564 0.0007477744427849489\n",
      "pixel686 0.0007425162018882924\n",
      "pixel634 0.0007423959175746288\n",
      "pixel230 0.0007359743646913264\n",
      "pixel708 0.0007325643724035593\n",
      "pixel414 0.0007282334852774767\n",
      "pixel274 0.0007184379006929116\n",
      "pixel202 0.0006888297276130432\n",
      "pixel358 0.000669770799212186\n",
      "pixel711 0.0006621266397139023\n",
      "pixel710 0.0006482550024838002\n",
      "pixel313 0.0006367117037111629\n",
      "pixel713 0.0006152938173122035\n",
      "pixel712 0.0006057868097153245\n",
      "pixel536 0.0006002310246835068\n",
      "pixel130 0.0005824242812212014\n",
      "pixel687 0.0005761499255435807\n",
      "pixel161 0.0005666827676181191\n",
      "pixel525 0.0005605901527911441\n",
      "pixel608 0.0005599121076596494\n",
      "pixel497 0.0005574423690936359\n",
      "pixel709 0.0005555208746997107\n",
      "pixel147 0.000555106697801665\n",
      "pixel581 0.000554516691518604\n",
      "pixel386 0.0005420637736174719\n",
      "pixel508 0.0005202063157012071\n",
      "pixel120 0.0005175841594589226\n",
      "pixel679 0.0005042896411698716\n",
      "pixel174 0.00048067907866724597\n",
      "pixel191 0.0004618972405202998\n",
      "pixel688 0.0004574380875439967\n",
      "pixel424 0.0004536659471864814\n",
      "pixel635 0.000452959129824934\n",
      "pixel526 0.0004486043847513464\n",
      "pixel131 0.00044247386599926766\n",
      "pixel103 0.00043958480983598785\n",
      "pixel330 0.0004328883118068078\n",
      "pixel678 0.00042250153553193806\n",
      "pixel592 0.00042191277844044083\n",
      "pixel662 0.0004180247185754615\n",
      "pixel94 0.00041754018133453397\n",
      "pixel452 0.00041273335907233977\n",
      "pixel275 0.0004098724047939782\n",
      "pixel715 0.0004044816679532742\n",
      "pixel717 0.0003986151068321942\n",
      "pixel257 0.0003948273342550342\n",
      "pixel714 0.0003831054582703843\n",
      "pixel442 0.0003817021440401314\n",
      "pixel649 0.0003778994212959083\n",
      "pixel716 0.0003727844429969545\n",
      "pixel95 0.0003715335993373664\n",
      "pixel609 0.00037067185539283414\n",
      "pixel285 0.00036953650213773814\n",
      "pixel302 0.00035858808476634863\n",
      "pixel554 0.00034320097707886334\n",
      "pixel470 0.00034272575784889756\n",
      "pixel498 0.0003422519805261197\n",
      "pixel162 0.00033640099849068466\n",
      "pixel582 0.0003318232016470822\n",
      "pixel229 0.0003221817536216504\n",
      "pixel71 0.0003186362104102577\n",
      "pixel689 0.0003182842468095537\n",
      "pixel173 0.00030146860184613786\n",
      "pixel201 0.00030139740196687533\n",
      "pixel312 0.0002882605053012255\n",
      "pixel368 0.00028028921092251353\n",
      "pixel284 0.00027969856657119376\n",
      "pixel707 0.00027442978212049367\n",
      "pixel739 0.00027189929979750267\n",
      "pixel636 0.0002687457028561382\n",
      "pixel620 0.0002614494841860526\n",
      "pixel563 0.0002562632554138748\n",
      "pixel663 0.00024035984384941075\n",
      "pixel396 0.00023679028222170723\n",
      "pixel741 0.0002344679849439878\n",
      "pixel591 0.00023173305044172038\n",
      "pixel677 0.00022813697358192297\n",
      "pixel718 0.0002268046363563862\n",
      "pixel146 0.000226644228394305\n",
      "pixel256 0.00022361368337343407\n",
      "pixel119 0.00022221588848943402\n",
      "pixel303 0.00022096189610899036\n",
      "pixel648 0.00021864839445570283\n",
      "pixel132 0.00021607646824680848\n",
      "pixel93 0.000214067805208581\n",
      "pixel340 0.00021369973701869518\n",
      "pixel415 0.00021254017283233798\n",
      "pixel248 0.0002085162244378652\n",
      "pixel690 0.0002081370491776445\n",
      "pixel276 0.00020446713201805776\n",
      "pixel499 0.00018238044901595186\n",
      "pixel200 0.00017570974842602674\n",
      "pixel637 0.00017524602551823327\n",
      "pixel706 0.00017194764606564102\n",
      "pixel535 0.00016360037606007427\n",
      "pixel331 0.0001592694897998838\n",
      "pixel443 0.0001586250503471579\n",
      "pixel228 0.00015690979148283164\n",
      "pixel691 0.00015034521892491154\n",
      "pixel744 0.0001501362806946639\n",
      "pixel507 0.00014860836336716654\n",
      "pixel387 0.00014712862369688055\n",
      "pixel163 0.0001463125316938297\n",
      "pixel742 0.00014362307094521322\n",
      "pixel738 0.00014165479960206762\n",
      "pixel527 0.0001405884281775292\n",
      "pixel610 0.0001400050820930841\n",
      "pixel471 0.00013537057199982714\n",
      "pixel743 0.00013397578427865059\n",
      "pixel451 0.00012440950990818766\n",
      "pixel133 0.00012361281516147196\n",
      "pixel664 0.00012352938896046997\n",
      "pixel555 0.00012301436248446558\n",
      "pixel92 0.00012010183703662895\n",
      "pixel68 0.00011977869633761413\n",
      "pixel70 0.00011876124037695193\n",
      "pixel619 0.00011812962141111361\n",
      "pixel705 0.00011588272100281675\n",
      "pixel73 0.00011139153660148372\n",
      "pixel740 0.00011031432739711944\n",
      "pixel69 0.00011001041147111641\n",
      "pixel479 0.00010908940666586449\n",
      "pixel583 0.0001073814117090796\n",
      "pixel145 0.00010732193469424046\n",
      "pixel676 0.00010717121354367327\n",
      "pixel227 0.00010683023973498008\n",
      "pixel172 0.00010653767178134502\n",
      "pixel91 0.00010580520827575516\n",
      "pixel66 0.00010299523047532292\n",
      "pixel283 0.00010156392974690462\n",
      "pixel220 0.00010139567963293964\n"
     ]
    }
   ],
   "source": [
    "for feature, imp_score in sorted(zip(digit_dataset.columns, \\\n",
    "                                    rnd_clf.feature_importances_), key=lambda x: x[1], reverse=True):\n",
    "    if(imp_score > 0.0001):\n",
    "        print(feature, imp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_y_pred = rnd_clf.predict(digit_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(digit_y_train, digit_y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9664259789444235\n"
     ]
    }
   ],
   "source": [
    "digit_y_test_pred = rnd_clf.predict(digit_X_test)\n",
    "print(f1_score(digit_y_test, digit_y_test_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost\n",
    "*combine multiple week learner to make good prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),\n",
       "                   learning_rate=0.5, n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=2), n_estimators=500,\n",
    "        algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42\n",
    "    )\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.856"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = ada_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cap = tree_reg1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y - y_cap\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg3.fit(X, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2, random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4 = y3 - tree_reg3.predict(X)\n",
    "tree_reg4 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg4.fit(X, y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x Sample : 0.45071430640991617\n",
      "y - value: 0.594479790484422\n"
     ]
    }
   ],
   "source": [
    "print(\"x Sample :\", X[1,0])\n",
    "print(\"y - value:\", y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ((i*10 for i in range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
